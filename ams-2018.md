Scaling Scientific Python
-------------------------

<img src="images/dask_horizontal_white.svg" width="30%">
<img src="images/xarray.png" width=30%>
<img src="images/jupyterhub.svg" width=30%>

*Matthew Rocklin*

Anaconda Inc.


What to expect
--------------

1.  **Scaling computation**
    -  Scaling NumPy with Dask
    -  Labeled and Indexed arrays with XArray
    -  Examples on HPC machines
2.  **Scaling users**
    -  JupyterHub deployments
    -  Cloud data storage
    -  Interactive examples on Google Compute Engine


### Problem: Our ability to produce datasets

<hr>

### Has outstripped our ability to analyze them


### Problem: Our ability to produce datasets

<hr>

### Has outstripped our ability to *analyze* them


### The Numeric Python Ecosystem

-  NumPy, Pandas, Scikit-Learn, Matplotlib, ...

<hr>

### Serves Scientific Communities

-  High performance implementations
-  Usable by non-experts
-  Composed of thousands of libraries that work well together

<hr>

### ... but these don't scale out well


<iframe width="560" height="315"
src="https://www.youtube.com/embed/cxcq35aruG0?ecver=1" frameborder="0"
gesture="media" allow="encrypted-media" allowfullscreen></iframe>

-  NumPy: combines interaction with C speeds
-  Dask.array: Scales NumPy



### Dask.array scales Numpy

<img src="images/dask-array.svg" width="60%">

    # NumPy code
    import numpy as np
    x = np.random.random((1000, 1000))
    u, s, v = np.linalg.svd(x.dot(x.T))

    # Dask.array code
    import dask.array as da
    x = da.random.random((100000, 100000), chunks=(1000, 1000))
    u, s, v = da.linalg.svd(x.dot(x.T))


<img src="http://dask.pydata.org/en/latest/_images/dask_horizontal_white.svg"
     alt="dask logo"
     width="30%">

<img src="images/grid_search_schedule.gif" width="100%">

-  General purpose dynamic task scheduler for computation
-  Handles data locality, resilience, work stealing, etc..
-  Native Python library that respects Python protocols
-  Lightweight and well supported
-  Does arrays, dataframes, machine learning, ...


### Dask does many other things

<hr>

### We're not going to talk about them here

<hr>

### But you might watch this video instead:

<iframe width="560" height="315"
src="https://www.youtube.com/embed/RA_2qdipVng" frameborder="0" gesture="media"
allow="encrypted-media" allowfullscreen></iframe>



### XArray: netCDF meets Pandas DataFrames

<img src="images/xarray-boxes-2.png" alt="XArray" width="100%">

```python
# xarray style
>>> ds.sel(time='2018-01-08').max(dim='ensemble')

# numpy Style
>>> array[[0, 1, 2, 3], :, :].max(axis=2)
```

*Taken from Stephan Hoyer's [ECMWF talk](https://docs.google.com/presentation/d/16CMY3g_OYr6fQplUZIDqVtG-SKZqsG8Ckwoj2oOqepU/edit#slide=id.g2b68f9254d_1_27)*


### XArray: makes scalable data analysis easy

```python
import xarray
ds = xarray.open_mfdataset('all/your/data/*.nc')            # Open many files
climatology = ds.groupby('time.season').mean('time')        # Compute seasonal average
temperature_range = abs(climatology.air.sel(season='JJA')   # Compare seasons
                      - climatology.air.sel(season='DJF'))
temperature_range.plot()                                    # Visualize
```

<hr>

### Feels native for geoscience community

### But general purpose, and integrates with wider ecosystem


### XArray on NetCDF Data

<iframe width="560" height="315"
src="https://www.youtube.com/embed/bQs11nBKix4?ecver=1" frameborder="0"
gesture="media" allow="encrypted-media" allowfullscreen></iframe>


Scalable Analysis of Atmospheric Data
-------------------------------------

We now have an intuitive and scalable analytics system

-  **NumPy** for in-memory computation
-  **Dask** for blocked parallel algorithms
-  **XArray** for dataset management and last-mile user support
-  **Jupyter, matplotlib, h5py, ...** for all the rest


### Moving from local to cluster computing is hard

1.  **Computationally** hard to build parallel algorithms
2.  **Administratively** hard to manage machines
    1.  How do I log on?
    2.  How do I pay for this?
    3.  Can other people see my data?
    4.  How do I give other people my data?
    5.  Wait, my old data format's might not work?
    6.  ...


### For Cheyenne at UCAR

1.  Fill out form and get mailed security key
2.  SSH into cluster, set up environment
3.  Launch Dask scheduler and workers with PBS
4.  Launch Jupyter server
5.  SSH tunnel into Jupyter, Dask dashboard
6.  Play
7.  For help, see [pangeo-data.github.io/pangeo/](https://pangeo-data.github.io/pangeo/)


### Cloud?

-  Benefits
    -  Easier broader access for new users
    -  Dynamic deployments for cost savings
    -  Leverage cloud providers (AWS, Google, Microsoft)
    -  Open internet, easier to build services, etc.
-  Drawbacks
    -  Lower performance
    -  No POSIX file system for NetCDF
    -  New set of administrative skills to learn


### We gave this a shot

-  [pangeo.pydata.org](http://pangeo.pydata.org)
    -  Google Container Engine for hardware
    -  Kubernetes for infrastructure
    -  JupyterHub for notebooks and user management
    -  Data:
        -  FUSE + GCS
        -  Zarr (custom file format)
    -  Computation:
        -  Launch Dask on the same Kubernetes cluster
-  Others have done this too
    -  UK Met Office's JADE
    -  Anaconda Enterprise


### We gave this a shot

<iframe width="560" height="315"
src="https://www.youtube.com/embed/rSOJKbfNBNk?ecver=1" frameborder="0"
gesture="media" allow="encrypted-media" allowfullscreen></iframe>


### Quick progress report

-  *Disclaimer: This is all early stage*
-  Google / Kubernetes: Couldn't be happier
-  [JupyterHub](https://jupyterhub.readthedocs.io):
    -  Pleasant experience: [Zero to JupyterHub](https://zero-to-jupyterhub.readthedocs.io/en/latest/)
    -  Engaging developer community (thanks Yuvi and Chris!)
-  [Dask on Kubernetes](https://github.com/yuvipanda/daskernetes)
    -  Inspired by [Jasmin](https://github.com/cedadev/jasmin-dask) from [CEDADev](http://proj.badc.rl.ac.uk/cedaservices/) and [Jade](http://www.informaticslab.co.uk/projects/jade.html) at [UK Met](http://www.informaticslab.co.uk/) (Matt Pryor and Jacob Tomlinson)
    -  Few hundred lines of code, seems to get the job done
-  Data Access
    -   NetCDF + FUSE + [GCSFS](http://gcsfs.readthedocs.io/en/latest/)

        Familiar, but slow and buggy (but getting better)
    -   [Zarr](http://zarr.readthedocs.io/en/stable/) + [GCSFS](http://gcsfs.readthedocs.io/en/latest/)

        New, but fast and simpler to interact with


### Some of the people and organizations responsible

-  Alistair Miles - Oxford - CGGH
-  Jacob Tomlinson - UK Met Informatics Lab
-  Joe Hamman - NCAR - NSF/Pangeo
-  Martin Durant - Anaconda
-  Matthew Pryor - CEDADev
-  Matthew Rocklin - Anaconda - NSF/Pangeo, Moore
-  Ryan Abernathy - Columbia - NSF/Pangeo
-  Stephan Hoyer - Google
-  Yuvi Panda - UC Berkeley / Jupyter - Moore
-  Dask, XArray, Jupyter, ... communities

<img src="images/moore.png" width="20%">
<img src="images/Anaconda_Logo.png" width="20%">
<img src="images/NSF.png" width="10%">
<img src="images/DARPA_Logo.jpg" width="20%">
<img src="images/mo-logo.svg" width="20%">


### Some of the people and organizations responsible

-  Alistair Miles - Oxford - CGGH
-  Jacob Tomlinson - UK Met Informatics Lab
-  **Joe Hamman - NCAR - NSF/Pangeo**
-  Martin Durant - Anaconda
-  Matthew Pryor - CEDADev
-  Matthew Rocklin - Anaconda - NSF/Pangeo, Moore
-  Ryan Abernathy - Columbia - NSF/Pangeo
-  Stephan Hoyer - Google
-  **Yuvi Panda - UC Berkeley/Jupyter - Moore**
-  Dask, XArray, Jupyter, ... communities

<img src="images/moore.png" width="20%">
<img src="images/Anaconda_Logo.png" width="20%">
<img src="images/NSF.png" width="10%">
<img src="images/DARPA_Logo.jpg" width="20%">
<img src="images/mo-logo.svg" width="20%">


### Building this was easy

### Because we tapped community expertise

<hr>

### No person knows enough to build these systems


### Building this was easy

### Because we tapped community expertise

<hr>

### No organization knows enough to build these systems


### Encourage Multi-Organization Collaborations

-   Pangeo: NSF Earthcube award
    -  Columbia
    -  NCAR
    -  Anaconda Inc
    -  ...

    Arose from the XArray open source community
-   ...



### Questions?

-  [pangeo.pydata.org](http://pangeo.pydata.org)
-  conda install dask xarray jupyterhub -c conda-forge
-  pip install dask[distributed] xarray jupyterhub

<img src="images/dask_horizontal_white.svg" width="30%">
<img src="images/xarray.png" width=30%>
<img src="images/jupyterhub.svg" width=30%>

<img src="images/moore.png" width="20%">
<img src="images/Anaconda_Logo.png" width="20%">
<img src="images/NSF.png" width="10%">
<img src="images/DARPA_Logo.jpg" width="20%">
<img src="images/mo-logo.svg" width="20%">



History and Future Steps
------------------------

-  2013-09: XArray initial commit
-  2014-12: Dask first commit
-  2015-01: Dask arrays
-  2015-02: Dask bags
-  2015-03: Dask dataframes
-  2015-04: XArray uses Dask
-  .. long period of single-machine use ..
-  2015-09: Dask distributed scheduler first commit
-  2016-11: First Pangeo meeting at Columbia
-  2017-09: NSF Funds Pangeo (Columbia, NCAR, Anaconda)
-  2017-10: Dask/XArray on HPC
-  2017-11/12: Dask/XArray on Cloud
